---
id: f1
name: F1 Score
aliases: [f1, f1_score, eval_f1, train_f1, val_f1, f1_macro, f1_micro, f1_weighted]
shortDescription: Harmonic mean of precision and recall.
whatToLookFor:
  - Should increase over time.
  - Useful when you need to balance precision and recall.
  - 'Best for imbalanced datasets where accuracy can be misleading.'
  - 'If F1 is low but accuracy is high, you likely have class imbalance issues.'
visualizations:
  yDomain: [0, 1]
  healthy:
    data:
      - { step: 0, value: 0.15 }
      - { step: 10, value: 0.35 }
      - { step: 20, value: 0.55 }
      - { step: 30, value: 0.68 }
      - { step: 40, value: 0.76 }
      - { step: 50, value: 0.82 }
      - { step: 60, value: 0.86 }
      - { step: 70, value: 0.88 }
      - { step: 80, value: 0.90 }
      - { step: 90, value: 0.91 }
      - { step: 100, value: 0.91 }
    analysis: "Strong F1. Both precision and recall are improving together, indicating the model is learning to correctly identify positives without too many false positives or false negatives."
  unhealthy:
    stagnant:
      label: "Stagnant"
      data:
        - { step: 0, value: 0.15 }
        - { step: 10, value: 0.22 }
        - { step: 20, value: 0.28 }
        - { step: 30, value: 0.32 }
        - { step: 40, value: 0.35 }
        - { step: 50, value: 0.36 }
        - { step: 60, value: 0.37 }
        - { step: 70, value: 0.36 }
        - { step: 80, value: 0.38 }
        - { step: 90, value: 0.37 }
        - { step: 100, value: 0.38 }
      analysis: "Low F1. The model struggles to balance precision and recall. Either it's missing too many positives (low recall) or making too many false positive errors (low precision)."
    imbalanced:
      label: "Precision/Recall Tradeoff"
      data:
        - { step: 0, value: 0.15 }
        - { step: 10, value: 0.40 }
        - { step: 20, value: 0.55 }
        - { step: 30, value: 0.62 }
        - { step: 40, value: 0.58 }
        - { step: 50, value: 0.65 }
        - { step: 60, value: 0.55 }
        - { step: 70, value: 0.68 }
        - { step: 80, value: 0.52 }
        - { step: 90, value: 0.60 }
        - { step: 100, value: 0.58 }
      analysis: "Unstable F1. The model is oscillating between favoring precision and recall, unable to find a stable balance. This can indicate threshold sensitivity or inconsistent learning."
---
F1 score combines precision and recall into a single metric. It's the harmonic mean, so both need to be high for F1 to be high.

**Example:** if 99% of emails are not spam, a model that always predicts "not spam" gets 99% accuracy but 0% F1 on the spam class.
